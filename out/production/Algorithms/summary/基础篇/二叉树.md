# 二叉树 非线性表结构
### 一. 树、二叉树

#### 1. 树
1. 节点
    * 每个元素我们叫作“节点”；用来连线相邻节点之间的关系，我们叫作“父子关系”。
    * 父节点是同一个节点，所以它们之间互称为兄弟节点。我们把没有父节点的节点叫作根节点
    * 没有子节点的节点叫作叶子节点或者叶节点
2. 4个概念
    * 节点高度：节点到叶子节点的最长路径（边数）——从上往下
    * 节点深度：根节点到这个节点所经历的的边的个数——从下往上
    * 节点层数：节点的深度+1
    * 树的高度：根节点的高度
#### 2. 二叉树
每个**节点**最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。
* 满二叉树
> 叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫作满二叉树。
* 完全二叉树

> 叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫作**完全二叉树**

#### 3. 树的表示

一种是基于指针或者引用的二叉链式存储法

> 每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。

一种是基于数组的顺序存储法——会浪费比较多的数组存储空间

> 根节点存储在下标 i = 1 的位置，那左子节点存储在下标 2 * i = 2 的位置，右子节点存储在 2 * i + 1 = 3 的位置。以此类推，B 节点的左子节点存储在 2 * i = 2 * 2 = 4 的位置，右子节点存储在 2 * i + 1 = 2 * 2 + 1 = 5 的位置。

下标为 2 * i 的位置存储的就是左子节点，下标为 2 * i + 1 的位置存储的就是右子节点。反过来，下标为 i/2 的位置存储就是它的父节点。通过这种方式，我们只要知道根节点存储的位置（一般情况下，为了方便计算子节点，根节点会存储在下标为 1 的位置），这样就可以通过下标计算，把整棵树都串起来

#### 4. 二叉树的遍历

**前序遍历**、**中序遍历**和**后序遍历**

二叉树的前、中、后序遍历就是一个递归的过程，二叉树遍历的时间复杂度是 `O(n)`

- 前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。
- 中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。
- 后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。



### 二. 二叉查找树

二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。

> 二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。

#### 1. 查找操作

它等于我们要查找的数据，那就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。

```java
public class BinarySearchTree {
  private Node tree;
 
  public Node find(int data) {
    Node p = tree;
    while (p != null) {
      if (data < p.data) p = p.left;
      else if (data > p.data) p = p.right;
      else return p;
    }
    return null;
  }
 
  public static class Node {
    private int data;
    private Node left;
    private Node right;
 
    public Node(int data) {
      this.data = data;
    }
  }
}
```

根节点的左右子树极度不平衡，已经退化成了链表，所以查找的时间复杂度就变成了 O(n)。

时间复杂度其实都跟树的高度成正比，也就是 O(height)。

#### 2. 为什么还要用二叉查找树

> 散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 `O(1)`，非常高效。而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 `O(logn)`，相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢？
>

第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 `O(n)` 的时间复杂度内，输出有序的数据序列。

第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 `O(logn)`。

第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 `logn` 小，所以实际的查找速度可能不一定比 `O(logn)` 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。

第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。

最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。

##### 

### 三. 平衡二叉查找树、红黑树

极端情况下，二叉树会退化为链表，时间复杂度会退化到 O(n)

平衡二叉树的严格定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于 1。

发明平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题。

**平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些**

#### 1. 定义

红黑树的英文是“Red-Black Tree”，简称 R-B Tree。它是一种不严格的平衡二叉查找树，我前面说了，它的定义是不严格符合平衡二叉查找树的定义的。

红黑树中的节点，一类被标记为黑色，一类被标记为红色。

- 根节点是黑色的；
- 每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；
- 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；
- 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

**“平衡”的意思可以等价为性能不退化。“近似平衡”就等价为性能不会退化的太严重**。

#### 2. 利弊

AVL 树是一种高度平衡的二叉树，所以查找的效率非常高，但是，有利就有弊，AVL 树为了维持这种高度的平衡，就要付出更多的代价。每次插入、删除都要做调整，就比较复杂、耗时。所以，对于有频繁的插入、删除操作的数据集合，使用 AVL 树的代价就有点高了。

红黑树只是做到了近似平衡，并不是严格的平衡，所以在维护平衡的成本上，要比 AVL 树要低。

所以，红黑树的插入、删除、查找各种操作性能都比较稳定。对于工程应用来说，要面对各种异常情况，为了支撑这种工业级的应用，我们更倾向于这种性能稳定的平衡二叉查找树。



### 四. 递归树



### 五. 做题技巧

#### 1. 递归

- 写出结束条件
- 不要把树复杂化，就当做树是三个节点，根节点，左子节点，右子节点
- 只考虑当前做什么，不用考虑下次应该做什么
- 每次调用应该返回什么

#### 2.迭代

### 六. 练习题

##### 1. [剑指 Offer 68 - I. 二叉搜索树的最近公共祖先](https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-zui-jin-gong-gong-zu-xian-lcof/)

##### 2. [257. 二叉树的所有路径](https://leetcode-cn.com/problems/binary-tree-paths/)